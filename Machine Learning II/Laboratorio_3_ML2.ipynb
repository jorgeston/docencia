{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c237d951-1ff0-49c3-8e5e-b46257242b1d",
   "metadata": {},
   "source": [
    "# Prediciendo la enfermedad cardiaca usando regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3852e-1752-4c8d-8089-a3132b17ef7f",
   "metadata": {},
   "source": [
    "El dataset Framingham Heart Study es un conjunto de datos famoso en el campo de la epidemiología y la medicina. La ciudad de Framingham, Massachusetts, en los Estados Unidos, ha sido la sede de un estudio a largo plazo sobre la salud del corazón que comenzó en 1948. Desde entonces, los datos recopilados en Framingham han sido vitales para nuestra comprensión de la enfermedad cardiovascular.\n",
    "\n",
    "El estudio de Framingham fue uno de los primeros en identificar la hipertensión, el colesterol alto, el tabaquismo, la obesidad, la diabetes y otros factores como riesgos clave para el desarrollo de enfermedades del corazón. Los investigadores han seguido a miles de participantes durante décadas, recopilando datos sobre su salud, sus hábitos de vida y sus condiciones médicas.\n",
    "\n",
    "## Descripción de las variables\n",
    "\n",
    "* male: si es hombre o no (cateegorica)\n",
    "* education: nivel educativo (categorica)\n",
    "* currentSmoker: si fuma o no (categorica)\n",
    "* cigsPerDay: numero de cigarros que fuma por dia (continua)\n",
    "* BPMeds: si el paciente ha tomado medicamentos para la presion arterial (categorica)\n",
    "* prevalentStroke: si el paciente ha tenido un ACV (categorica)\n",
    "* prevalentHyp: si el paciente es hipertenso (cat)\n",
    "* diabetes: idem diabetes\n",
    "* totChol: nivel de colesterol (cont)\n",
    "* sysBP: presion arterial sistolica (cont)\n",
    "* diaBP: presion arterial diastolica (cont)\n",
    "* BMI: Indice de masa corporal (cont)\n",
    "* heartRate: frecuencia cardiaca (cont)\n",
    "* glucose: nivel de glucosa (cont)\n",
    "* TenYearCHD: Riesgo de 10 años de cardiopatía coronaria CHD (esta sera nuestra variable target)\n",
    "\n",
    "Es importante recordar que aunque los datos del estudio de Framingham han proporcionado muchas ideas valiosas sobre la enfermedad del corazón, los participantes en el estudio son predominantemente de raza blanca y de un área geográfica específica, por lo que los hallazgos pueden no ser generalizables a todas las poblaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087fa307-8288-421e-b360-60fbee75c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db8a402-3da1-4258-b85f-738127dc98d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('framingham.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d8d2f-689d-45b1-82e1-588f52682814",
   "metadata": {},
   "source": [
    "## Analisis exploratorio y pre-procesamiento de datos\n",
    "\n",
    "Acá se deben ver como se distirbuyen las variables, descartar las que estan correlacionadas entre si, y tratar los valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408fcfb5-d24b-4854-8278-d798bcdd926e",
   "metadata": {},
   "source": [
    "Por simplicidad y en vista de querer evitar posibles colinealidades, vamos a descartar algunas variables que parecen ser redundantes con otras. Por ejemplo, 0 cigarros por día es equivalente a que no fume. La presió diastólica por lo general está muy correlacionada con la sistólica, y las presión alta está determinada principalmente por esta última. La variable de glucosa se eliminará también, favorenciendo a la variable categórica de la prevalencia de diabetes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb32e50-687a-4043-996c-1999f6a735d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['currentSmoker','diaBP','glucose'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45eb83-56d1-4f4c-9529-b20a7fffbe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05957aa0-3f37-421e-af60-a528ac06ae28",
   "metadata": {},
   "source": [
    "Vamos a tratar los valores faltantes eliminándolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3afb1b0-b92c-40dc-979e-9db3fc62d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61fd069-d555-4d2d-a83f-b6381f3b966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5661a4-676e-44e9-a8d1-495074fd4fd8",
   "metadata": {},
   "source": [
    "## Preparación de los datos para el modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b41e72-2f47-46b9-a7d4-2b6aed60597a",
   "metadata": {},
   "source": [
    "Ahora, debemos tratar los atributos que son categóricos. Recordar que se debe borrar una categoría base para evitar la multicolinealidad perfecta o \"trampa de la variable dummy\". Esta vez lo haremos usando el argumento drop_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed4ee49-8bdf-4851-a566-e9b77e45822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_male = pd.get_dummies(df.male, drop_first=True) \n",
    "dummies_education = pd.get_dummies(df.education, drop_first=True)\n",
    "dummies_BPMeds = pd.get_dummies(df.BPMeds, drop_first=True)\n",
    "dummies_prevalentStroke= pd.get_dummies(df.prevalentStroke, drop_first=True)\n",
    "dummies_prevalentHyp = pd.get_dummies(df.prevalentHyp, drop_first=True)\n",
    "dummies_diabetes = pd.get_dummies(df.diabetes , drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bbd85-970e-4602-b3c3-e25e0ae3c2a3",
   "metadata": {},
   "source": [
    "Para evitar confusiones a la hora de interpretar el output del modelo, cambiamos los nombres de la columna dummie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca33567-bc0f-4d8b-aad2-ab9ceb14fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_male.columns = ['male']\n",
    "dummies_education.columns = ['educ_2','educ_3','educ_4']\n",
    "dummies_BPMeds.columns = ['prev_BPMeds']\n",
    "dummies_prevalentStroke.columns = ['prev_stroke']\n",
    "dummies_prevalentHyp.columns = ['prev_hyp']\n",
    "dummies_diabetes.columns = ['prev_diabetes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d6473f-bf58-4335-981b-1e503080e600",
   "metadata": {},
   "source": [
    "Ahora, empezamos a construir las matrices de atributos y de respuesta del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe34d9-4a15-413a-9496-654509c77787",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['male','education','BPMeds','prevalentStroke','prevalentHyp','diabetes','TenYearCHD'],axis=1)\n",
    "X = pd.concat([X, dummies_male, dummies_education,dummies_BPMeds, dummies_prevalentStroke,dummies_prevalentHyp, dummies_diabetes], axis =1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de41ad-1a8f-423c-96cf-4a757baf596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['TenYearCHD']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4301065-af15-4fbd-9b4f-f046eda61e66",
   "metadata": {},
   "source": [
    "Ahora separamos entre entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3bfdd8-663d-424a-8a02-6629ec69a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084faf43-e980-4912-9e2f-e51151b7365f",
   "metadata": {},
   "source": [
    "Y ahora normalizamos la data (advertenecia: si este paso no se hace, saldrá una advertencia adelante: que el modelo no converge y se necesita aumentar el numero de iteraciones o bien, normalizar los datos, haga la prueba!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa77d28-fbaf-4e45-928f-7e1e39b839b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f165b15-6da7-405b-a6b4-fc2a413be37e",
   "metadata": {},
   "source": [
    "## Ajuste y predicción\n",
    "\n",
    "El clásico fit y predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61ee981-f962-47ac-8122-391e17dfe4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78ec4c-a6cd-4ac0-b652-20af9ec8ffcb",
   "metadata": {},
   "source": [
    "Imprimimos los coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fccb50-64fc-4d38-a1af-d332718cede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Coeficientes : {model.coef_}')\n",
    "print(f'Sesgo : {model.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b5590-4a7a-4556-a8c8-27b6986bf579",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60691ce0-1387-4540-96df-6e61d1d220e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.coef_, columns =X.columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8dee0-41c9-4711-925f-e99d84806929",
   "metadata": {},
   "source": [
    "Obtenemos los odd ratios a partir de la exponencial de los coeficientes. Recordar que los valores mayores 1 influye positivamente en la probabilidad del target (enfermedad coronaria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b45b6f3-ef6e-4b01-a104-cccf8eb1dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pd.DataFrame(np.exp(model.coef_), columns =X.columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa91eb-dc6e-4ef4-a629-7025bda15b12",
   "metadata": {},
   "source": [
    "¿Cómo anda el sobreajuste?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc6471-ca9d-471c-a5e1-18d0424b78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test accuracy: {model.score(X_test,y_test)}')\n",
    "print(f'Train accuracy: {model.score(X_train,y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538ff92-3a9d-4673-9d89-4879202d59c3",
   "metadata": {},
   "source": [
    "## Evaluación\n",
    "\n",
    "Calcular metricas de evaluacion, ROC y AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ff30d-de0f-4e5e-84b3-7b351adacfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matriz_confusion = pd.DataFrame(confusion_matrix(y_test, y_pred), columns = ['Predicted Positive', 'Predicted Negative'], \n",
    "                  index=['Actual Positive', 'Actual Negative'])\n",
    "matriz_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687aea7-df2a-4a10-ab8d-1d3a2d889a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce659cd-a0d3-4975-8a86-c23db6f90c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test,y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, ))\n",
    "print(\"Recall:\", recall_score(y_test,y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b0d9d-8065-4a55-8a6a-537e0239f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area Under Curve - AUC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "model_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % model_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim(([0.0, 1.0]))\n",
    "plt.ylim(([0.0, 1.05]))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd3df8-4665-48f6-b830-5f4dab7af623",
   "metadata": {},
   "source": [
    "¿Se puede enmendar el modelo?\n",
    "\n",
    "¿qué puede haber pasado?\n",
    "\n",
    "Como dice la metodología CRISP-DM, debemos ir hacia atrás\n",
    "\n",
    "Veamos cómo anda la clase target, que fue un paso que no hicimos antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ab5ae-e41b-4354-84a5-621f1f3e13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(df.TenYearCHD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4113b8-1e06-45e8-b062-97b60d1d2abb",
   "metadata": {},
   "source": [
    "Estamos frente a **datos desbalanceados**, y esto se podría haber pensando desde la comprensión del problema. La enfermedad coronaria es algo raro, no masivo, afortundamente, por lo tanto, es de esperar que se tengan datos desbalanceados en cualquier muestra. Si esto pasa, es porque el modelo está reconociendo más las clase \"0\" y muy poco la clase \"1\". Esto ya lo podemos sospechar desde los valores de la precisión y la sensibilidad.\n",
    "\n",
    "Existen diversas técnica de balanceo de clases. Una de ellas es SMOTE, que lo que hace -coloquialmente hablando- es simular más datos de la clase desfavorecida cosa de balancear el problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84c907-f4d7-4e20-b84a-0cc67e387f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b69170-0162-4987-aea8-b2a57e95b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "clf = LogisticRegression()\n",
    "model_res = clf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620b5e8-f8c1-4514-b251-c31e840f918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "model_roc_auc = roc_auc_score(y_test, model_res.predict(X_test))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model_res.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % model_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim(([0.0, 1.0]))\n",
    "plt.ylim(([0.0, 1.05]))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8a5ab-41a4-492f-8bb7-b5f4cd966312",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "- Calcular matriz de confusión, y medidas de evaluación del nuevo modelo balanceado\n",
    "- Ver si con otra selección de variables este modelo mejora su evaluación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c85d98-5f04-4383-891b-f1c6e5fd75c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-interpretando\n",
    "\n",
    "pd.DataFrame(np.exp(model_res.coef_), columns =X.columns )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
